{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cust_id lookalike1_id    score1 lookalike2_id    score2 lookalike3_id  \\\n",
      "0    C0001         C0107  0.989362         C0137  0.987831         C0191   \n",
      "1    C0002         C0142  0.990076         C0043  0.975826         C0186   \n",
      "2    C0003         C0190  0.917195         C0133  0.912769         C0174   \n",
      "3    C0004         C0113  0.994264         C0165  0.985470         C0102   \n",
      "4    C0005         C0123  0.999781         C0078  0.998505         C0097   \n",
      "5    C0006         C0168  0.953841         C0048  0.907481         C0187   \n",
      "6    C0007         C0140  0.997960         C0092  0.997904         C0078   \n",
      "7    C0008         C0084  0.926548         C0109  0.926376         C0090   \n",
      "8    C0009         C0198  0.987412         C0060  0.972610         C0014   \n",
      "9    C0010         C0166  0.964472         C0199  0.941327         C0073   \n",
      "10   C0011         C0107  0.985363         C0048  0.985288         C0001   \n",
      "11   C0012         C0102  0.987787         C0155  0.985784         C0104   \n",
      "12   C0013         C0155  0.991269         C0188  0.988887         C0099   \n",
      "13   C0014         C0060  0.999450         C0198  0.995284         C0063   \n",
      "14   C0015         C0058  0.995609         C0020  0.994860         C0033   \n",
      "15   C0016         C0183  0.957211         C0154  0.904596         C0117   \n",
      "16   C0017         C0124  0.986021         C0075  0.975864         C0041   \n",
      "17   C0018         C0046  0.877332         C0122  0.843563         C0068   \n",
      "18   C0019         C0172  0.993128         C0127  0.903901         C0069   \n",
      "19   C0020         C0058  0.995683         C0015  0.994860         C0033   \n",
      "\n",
      "      score3  \n",
      "0   0.971885  \n",
      "1   0.949561  \n",
      "2   0.879583  \n",
      "3   0.978703  \n",
      "4   0.997862  \n",
      "5   0.903427  \n",
      "6   0.992619  \n",
      "7   0.918945  \n",
      "8   0.971613  \n",
      "9   0.932137  \n",
      "10  0.966321  \n",
      "11  0.980031  \n",
      "12  0.988480  \n",
      "13  0.992519  \n",
      "14  0.993883  \n",
      "15  0.875760  \n",
      "16  0.933190  \n",
      "17  0.821808  \n",
      "18  0.887244  \n",
      "19  0.993973  \n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load datasets\n",
    "customers = pd.read_csv('Customers.csv')\n",
    "products = pd.read_csv('Products.csv')\n",
    "transactions = pd.read_csv('Transactions.csv')\n",
    "\n",
    "# Merge transactions with customers and products for enriched data\n",
    "transactions = transactions.merge(customers, on='CustomerID', how='left')\n",
    "transactions = transactions.merge(products, on='ProductID', how='left')\n",
    "\n",
    "# Create a customer profile feature set\n",
    "customer_profiles = transactions.groupby('CustomerID').agg({\n",
    "    'TotalValue': 'sum',          # Total spending\n",
    "    'Quantity': 'sum',            # Total quantity purchased\n",
    "    'ProductID': 'count',         # Product diversity (proxy for frequency)\n",
    "    'Region': 'first'             # Region information\n",
    "}).reset_index()\n",
    "\n",
    "# Rename 'ProductID' aggregation for clarity\n",
    "customer_profiles.rename(columns={'ProductID': 'ProductCount'}, inplace=True)\n",
    "\n",
    "# One-hot encode the 'Region' column\n",
    "customer_profiles = pd.get_dummies(customer_profiles, columns=['Region'], drop_first=True)\n",
    "\n",
    "# Standardise numerical features for similarity calculation\n",
    "scaler = StandardScaler()\n",
    "numerical_features = ['TotalValue', 'Quantity', 'ProductCount']\n",
    "customer_profiles[numerical_features] = scaler.fit_transform(customer_profiles[numerical_features])\n",
    "\n",
    "# Compute Cosine Similarity\n",
    "# Extract features for similarity calculation\n",
    "features = customer_profiles.drop(columns=['CustomerID']).values\n",
    "similarity_matrix = cosine_similarity(features)\n",
    "\n",
    "# Build the Lookalike Recommendations\n",
    "def get_top_3_lookalikes(customer_id, customer_profiles, similarity_matrix):\n",
    "    # Get the index of the given customer\n",
    "    customer_index = customer_profiles[customer_profiles['CustomerID'] == customer_id].index[0]\n",
    "    \n",
    "    # Fetch similarity scores for this customer\n",
    "    similarity_scores = list(enumerate(similarity_matrix[customer_index]))\n",
    "    \n",
    "    # Exclude the customer themselves and sort by similarity scores\n",
    "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "    similarity_scores = [score for score in similarity_scores if score[0] != customer_index]\n",
    "    \n",
    "    # Get the top 3 similar customers\n",
    "    top_3 = similarity_scores[:3]\n",
    "    top_3_customers = [\n",
    "        (customer_profiles.iloc[entry[0]]['CustomerID'], entry[1]) for entry in top_3\n",
    "    ]\n",
    "    return top_3_customers\n",
    "\n",
    "# Generate lookalikes for the first 20 customers\n",
    "lookalike_results = {}\n",
    "for customer_id in customer_profiles['CustomerID'][:20]:\n",
    "    lookalike_results[customer_id] = get_top_3_lookalikes(customer_id, customer_profiles, similarity_matrix)\n",
    "\n",
    "# Create a Lookalike.csv file\n",
    "lookalike_data = []\n",
    "for customer_id, lookalikes in lookalike_results.items():\n",
    "    lookalike_data.append({\n",
    "        'cust_id': customer_id,\n",
    "        'lookalike1_id': lookalikes[0][0],\n",
    "        'score1': lookalikes[0][1],\n",
    "        'lookalike2_id': lookalikes[1][0],\n",
    "        'score2': lookalikes[1][1],\n",
    "        'lookalike3_id': lookalikes[2][0],\n",
    "        'score3': lookalikes[2][1],\n",
    "    })\n",
    "\n",
    "lookalike_df = pd.DataFrame(lookalike_data)\n",
    "lookalike_df.to_csv('Lookalike.csv', index=False)\n",
    "\n",
    "# Display the Lookalike DataFrame\n",
    "print(lookalike_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
